{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53ff0153a493432aacb6a291aaea0629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e72a68747aac495b9926eabc72c9716f",
              "IPY_MODEL_a66eb3a7f6904b468fd73fbe77ef004f",
              "IPY_MODEL_97d68601ae194a91abbb30d1054fd122"
            ],
            "layout": "IPY_MODEL_41dfe437055f4892a13f27cc8b6de23f"
          }
        },
        "e72a68747aac495b9926eabc72c9716f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2918b8e585b420c9ef9c4d2d5ff9e39",
            "placeholder": "​",
            "style": "IPY_MODEL_3a4b124a2da84dad9142b7a6c9af7db8",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "a66eb3a7f6904b468fd73fbe77ef004f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7590f4bb1fca461aa7893f82999e21e5",
            "max": 12337299197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78227ed432794353b02458788ee6e0a0",
            "value": 12337299197
          }
        },
        "97d68601ae194a91abbb30d1054fd122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c67ee085b674b9a82ce2368b0276a08",
            "placeholder": "​",
            "style": "IPY_MODEL_e011b6fbbc374ebe9e882fc74dec0077",
            "value": " 12.3G/12.3G [01:14&lt;00:00, 50.2MB/s]"
          }
        },
        "41dfe437055f4892a13f27cc8b6de23f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2918b8e585b420c9ef9c4d2d5ff9e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a4b124a2da84dad9142b7a6c9af7db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7590f4bb1fca461aa7893f82999e21e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78227ed432794353b02458788ee6e0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c67ee085b674b9a82ce2368b0276a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e011b6fbbc374ebe9e882fc74dec0077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwangunlee/kdi/blob/master/KoGPT_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 카카오브레인의 KoGPT는Colab Pro를 사용하지 않는한 메모리 부족으로 작동 안됨\n",
        "kakaobrain/kogpt\n",
        "https://huggingface.co/kakaobrain/kogpt\n",
        "\n",
        "# SKT의 KoGPT를 사용함\n",
        "skt/kogpt2-base-v2\n",
        "https://github.com/SKT-AI/KoGPT2\n",
        "\n",
        "skt/ko-gpt-trinity-1.2B-v0.5\n",
        "https://huggingface.co/skt/ko-gpt-trinity-1.2B-v0.5/blob/main/README.md\n"
      ],
      "metadata": {
        "id": "sPvHsukCKiwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "wWDqYfIUwHoO",
        "outputId": "8f68d374-9d39-4aa5-c10a-147c53fd65a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  4 07:27:11 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc4ga8D4mu2f",
        "outputId": "ad540c66-89b8-469f-d811-3a417e0a6e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 10 02:12:50 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    26W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "8ghUJtQwnDl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbfbd6ee-1134-42d4-fb86-5d6762edb766"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SKT Ko-GPT 토크나이저\n",
        "\n",
        "text = \"자연 언어 처리에서 말하는 형태소 분석이란 어떤 대상 어절을 최소의 의미 단위인 '형태소'로 분석하는 것을 의미한다. (형태소는 단어 그 자체가 될 수도 있고, 일반적으로는 단어보다 작은 단위이다.) 정보 검색 엔진에서 한국어의 색인어 추출에 많이 사용한다. 형태소 분석 단계에서 문제가 되는 부분은 미등록어, 오탈자, 띄어쓰기 오류 등에 의한 형태소 분석의 오류, 중의성이나 신조어 처리 등이 있는데, 이들은 형태소 분석에 치명적인 약점이라 할 수 있다. 복합 명사 분해도 형태소 분석의 어려운 문제 중 하나이다. 복합 명사란 하나 이상의 단어가 합쳐서 새로운 의미를 생성해 낸 단어로 '봄바람' 정보검색' '종합정보시스템' 등을 그 예로 들 수 있다. 이러한 단어는 한국어에서 띄어쓰기에 따른 형식도 불분명할 뿐만 아니라 다양한 복합 유형 등에 따라 의미의 통합이나 분해가 다양한 양상을 보이기 때문에 이들 형태소를 분석하는 것은 매우 어려운 문제이다. 기계적으로 복합명사를 처리하는 방식 중의 하나는, 음절 단위를 기반으로 하는 bi-gram이 있다. 예를 들어, '복합 명사'는 음절 단위로 '복합+명사', '복+합명사', '복합명+사'의 세 가지 형태로 쪼갤 수 있고, 이 중 가장 적합한 분해 결과를 문서 내에서 출현하는 빈도 등의 추가 정보를 통해 선택하는 알고리즘이 있을 수 있다. 일반적으로, 다양하게 쪼개지는 분석 결과들 중에서 적합한 결과를 선택하기 위해, 테이블 파싱이라는 동적 프로그래밍 방법을 사용한다.\"\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>')\n",
        "tokenizer.tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP3XAUGTMqly",
        "outputId": "f10aa150-275c-4d28-baae-b9891dc6e330"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁자연',\n",
              " '▁언어',\n",
              " '▁처리',\n",
              " '에서',\n",
              " '▁말하는',\n",
              " '▁형태',\n",
              " '소',\n",
              " '▁분석',\n",
              " '이란',\n",
              " '▁어떤',\n",
              " '▁대상',\n",
              " '▁어',\n",
              " '절을',\n",
              " '▁최',\n",
              " '소의',\n",
              " '▁의미',\n",
              " '▁단위인',\n",
              " \"▁'\",\n",
              " '형태',\n",
              " '소',\n",
              " \"'로\",\n",
              " '▁분석하는',\n",
              " '▁것을',\n",
              " '▁의미',\n",
              " '한다.',\n",
              " '▁(',\n",
              " '형태',\n",
              " '소는',\n",
              " '▁단어',\n",
              " '▁그',\n",
              " '▁자체가',\n",
              " '▁될',\n",
              " '▁수도',\n",
              " '▁있고,',\n",
              " '▁일반적으로는',\n",
              " '▁단어',\n",
              " '보다',\n",
              " '▁작은',\n",
              " '▁단위',\n",
              " '이다.',\n",
              " ')',\n",
              " '▁정보',\n",
              " '▁검색',\n",
              " '▁엔진',\n",
              " '에서',\n",
              " '▁한국',\n",
              " '어의',\n",
              " '▁색인',\n",
              " '어',\n",
              " '▁추출',\n",
              " '에',\n",
              " '▁많이',\n",
              " '▁사용한',\n",
              " '다.',\n",
              " '▁형태',\n",
              " '소',\n",
              " '▁분석',\n",
              " '▁단계에서',\n",
              " '▁문제가',\n",
              " '▁되는',\n",
              " '▁부분은',\n",
              " '▁미',\n",
              " '등록',\n",
              " '어,',\n",
              " '▁오',\n",
              " '탈',\n",
              " '자,',\n",
              " '▁띄',\n",
              " '어',\n",
              " '쓰기',\n",
              " '▁오류',\n",
              " '▁등에',\n",
              " '▁의한',\n",
              " '▁형태',\n",
              " '소',\n",
              " '▁분석',\n",
              " '의',\n",
              " '▁오',\n",
              " '류,',\n",
              " '▁중의',\n",
              " '성이나',\n",
              " '▁신조',\n",
              " '어',\n",
              " '▁처리',\n",
              " '▁등이',\n",
              " '▁있는데,',\n",
              " '▁이들은',\n",
              " '▁형태',\n",
              " '소',\n",
              " '▁분석',\n",
              " '에',\n",
              " '▁치명적인',\n",
              " '▁약',\n",
              " '점',\n",
              " '이라',\n",
              " '▁할',\n",
              " '▁수',\n",
              " '▁있다.',\n",
              " '▁복합',\n",
              " '▁명사',\n",
              " '▁분',\n",
              " '해도',\n",
              " '▁형태',\n",
              " '소',\n",
              " '▁분석',\n",
              " '의',\n",
              " '▁어려운',\n",
              " '▁문제',\n",
              " '▁중',\n",
              " '▁하나',\n",
              " '이다.',\n",
              " '▁복합',\n",
              " '▁명사',\n",
              " '란',\n",
              " '▁하나',\n",
              " '▁이상의',\n",
              " '▁단어가',\n",
              " '▁합쳐서',\n",
              " '▁새로운',\n",
              " '▁의미를',\n",
              " '▁생성',\n",
              " '해',\n",
              " '▁낸',\n",
              " '▁단',\n",
              " '어로',\n",
              " \"▁'\",\n",
              " '봄',\n",
              " '바람',\n",
              " \"'\",\n",
              " '▁정보',\n",
              " '검',\n",
              " '색',\n",
              " \"'\",\n",
              " \"▁'\",\n",
              " '종합',\n",
              " '정보',\n",
              " '시스템',\n",
              " \"'\",\n",
              " '▁등을',\n",
              " '▁그',\n",
              " '▁예로',\n",
              " '▁들',\n",
              " '▁수',\n",
              " '▁있다.',\n",
              " '▁이러한',\n",
              " '▁단어는',\n",
              " '▁한국',\n",
              " '어에서',\n",
              " '▁띄',\n",
              " '어',\n",
              " '쓰',\n",
              " '기에',\n",
              " '▁따른',\n",
              " '▁형식',\n",
              " '도',\n",
              " '▁불분명',\n",
              " '할',\n",
              " '▁뿐만',\n",
              " '▁아니라',\n",
              " '▁다양한',\n",
              " '▁복합',\n",
              " '▁유형',\n",
              " '▁등에',\n",
              " '▁따라',\n",
              " '▁의미의',\n",
              " '▁통합',\n",
              " '이나',\n",
              " '▁분해',\n",
              " '가',\n",
              " '▁다양한',\n",
              " '▁양상을',\n",
              " '▁보이기',\n",
              " '▁때문에',\n",
              " '▁이들',\n",
              " '▁형태',\n",
              " '소를',\n",
              " '▁분석하는',\n",
              " '▁것은',\n",
              " '▁매우',\n",
              " '▁어려운',\n",
              " '▁문제',\n",
              " '이다.',\n",
              " '▁기계',\n",
              " '적으로',\n",
              " '▁복합',\n",
              " '명',\n",
              " '사를',\n",
              " '▁처리하는',\n",
              " '▁방식',\n",
              " '▁중의',\n",
              " '▁하나는',\n",
              " ',',\n",
              " '▁음절',\n",
              " '▁단위를',\n",
              " '▁기반으로',\n",
              " '▁하는',\n",
              " '▁b',\n",
              " 'i',\n",
              " '-',\n",
              " 'gra',\n",
              " 'm',\n",
              " '이',\n",
              " '▁있다.',\n",
              " '▁예를',\n",
              " '▁들어,',\n",
              " \"▁'\",\n",
              " '복합',\n",
              " '▁명사',\n",
              " \"'는\",\n",
              " '▁음절',\n",
              " '▁단위로',\n",
              " \"▁'\",\n",
              " '복합',\n",
              " '+',\n",
              " '명사',\n",
              " \"',\",\n",
              " \"▁'\",\n",
              " '복',\n",
              " '+',\n",
              " '합',\n",
              " '명사',\n",
              " \"',\",\n",
              " \"▁'\",\n",
              " '복합',\n",
              " '명',\n",
              " '+',\n",
              " '사',\n",
              " \"'의\",\n",
              " '▁세',\n",
              " '▁가지',\n",
              " '▁형태로',\n",
              " '▁쪼',\n",
              " '갤',\n",
              " '▁수',\n",
              " '▁있고,',\n",
              " '▁이',\n",
              " '▁중',\n",
              " '▁가장',\n",
              " '▁적합한',\n",
              " '▁분해',\n",
              " '▁결과를',\n",
              " '▁문서',\n",
              " '▁내에서',\n",
              " '▁출현',\n",
              " '하는',\n",
              " '▁빈도',\n",
              " '▁등의',\n",
              " '▁추가',\n",
              " '▁정보를',\n",
              " '▁통해',\n",
              " '▁선택하는',\n",
              " '▁알고',\n",
              " '리즘',\n",
              " '이',\n",
              " '▁있을',\n",
              " '▁수',\n",
              " '▁있다.',\n",
              " '▁일반적으로',\n",
              " ',',\n",
              " '▁다양하게',\n",
              " '▁쪼개',\n",
              " '지는',\n",
              " '▁분석',\n",
              " '▁결과',\n",
              " '들',\n",
              " '▁중에서',\n",
              " '▁적합한',\n",
              " '▁결과를',\n",
              " '▁선택',\n",
              " '하기',\n",
              " '▁위해,',\n",
              " '▁테이',\n",
              " '블',\n",
              " '▁파',\n",
              " '싱',\n",
              " '이라는',\n",
              " '▁동적',\n",
              " '▁프로',\n",
              " '그래',\n",
              " '밍',\n",
              " '▁방법을',\n",
              " '▁사용한',\n",
              " '다.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SKT Ko-GPT 모델\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "text = '이관건은'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "gen_ids = model.generate(input_ids,\n",
        "                           max_length=128,\n",
        "                           repetition_penalty=2.0,\n",
        "                           pad_token_id=tokenizer.pad_token_id,\n",
        "                           eos_token_id=tokenizer.eos_token_id,\n",
        "                           bos_token_id=tokenizer.bos_token_id,\n",
        "                           use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys0Eo2gxMZHs",
        "outputId": "459ee868-c8a9-449c-be5a-19cfce283b0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이관건은 지난해 12월31일부터 올 1월1일로 연장됐다.\n",
            "이번 개정안은 오는 6월30일에 시행될 예정이다.\n",
            "개정안에 따르면 우선 '중소기업진흥공단 이사장 추천위원회'를 구성하고, 이달 중으로 중소기업중앙회로부터 추천을 받은 후보자를 대상으로 면접을 실시할 계획이다.\n",
            "또한 중기청장이 임명할 경우 해당 공단 임원의 임기를 1년에서 2년까지 연임 가능하도록 했다.\n",
            "아울러 현재 재직 중인 임원 가운데 임기 만료 후 3년 이내에 중도 퇴직한 경우에는 잔여 재임기간 동안 재취업을 제한하기로 했다.</d> 한국은행이 기준금리를 동결했다.\n",
            "한은은 9일 금융통화위원회를 열고 만장일치\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated"
      ],
      "metadata": {
        "id": "kITE-if-xPN9",
        "outputId": "d44d7742-049d-493a-c598-b0b506413500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'자연 언어 처리에서 말하는 형태소 분석이란 어떤 대상 어절을 최소의 의미 단위인 \\'형태소\\'로 분석하는 것을 의미한다. (형태소는 단어 그 자체가 될 수도 있고, 일반적으로는 단어보다 작은 단위이다.) 정보 검색 엔진에서 한국어의 색인어 추출에 많이 사용한다. 형태소 분석 단계에서 문제가 되는 부분은 미등록어, 오탈자, 띄어쓰기 오류 등에 의한 형태소 분석의 오류, 중의성이나 신조어 처리 등이 있는데, 이들은 형태소 분석에 치명적인 약점이라 할 수 있다. 복합 명사 분해도 형태소 분석의 어려운 문제 중 하나이다. 복합 명사란 하나 이상의 단어가 합쳐서 새로운 의미를 생성해 낸 단어로 \\'봄바람\\' 정보검색\\' \\'종합정보시스템\\' 등을 그 예로 들 수 있다. 이러한 단어는 한국어에서 띄어쓰기에 따른 형식도 불분명할 뿐만 아니라 다양한 복합 유형 등에 따라 의미의 통합이나 분해가 다양한 양상을 보이기 때문에 이들 형태소를 분석하는 것은 매우 어려운 문제이다. 기계적으로 복합명사를 처리하는 방식 중의 하나는, 음절 단위를 기반으로 하는 bi-gram이 있다. 예를 들어, \\'복합 명사\\'는 음절 단위로 \\'복합+명사\\', \\'복+합명사\\', \\'복합명+사\\'의 세 가지 형태로 쪼갤 수 있고, 이 중 가장 적합한 분해 결과를 문서 내에서 출현하는 빈도 등의 추가 정보를 통해 선택하는 알고리즘이 있을 수 있다. 일반적으로, 다양하게 쪼개지는 분석 결과들 중에서 적합한 결과를 선택하기 위해, 테이블 파싱이라는 동적 프로그래밍 방법을 사용한다. 테스트 결과, 텍스트의 구조나 구조를 단순화하거나 변형시키는 것이 가능하다. 따라서 개별 단어의 특성을 파악하고, 이를 바탕으로 한 맞춤형 분석을 수행할 때 보다 더 많은 양의 데이터를 얻을 수가 있다.\\n예를 들어 다음과 같은 경우처럼 여러 개의 단어를 하나의 문장으로 묶는 작업을 수행하면, 각각의 어휘를 하나로 묶어 놓은 다음 각 문장마다 다른 뜻을 가진 낱말의 이름을 붙여 놓을 필요가 없다.\\n또한 특정 문장을 구성하는 데 필요한 모든 데이터와 함께 해당 문장의 고유성을 나타내는 수식어를 입력해야 한다.\\n이를테면 \"\"(다음), \"이\",,\\n/ //이다\" 등. 이런 식으로 구성된 문장은 모두 합쳐진 것이다.\\n따라서 두 개 이상 겹치는 문장이 있으면 서로 연결되지 않는 경우가 많다.\\n그러나 이렇게 통합된 문장에 대한 분류 작업은 복잡한 과정을 거쳐야 하므로 복잡성이 크다.\\n그렇기 때문에, 단일 명사의 정의에는 몇 가지의 공통점이 존재한다.\\n첫째, 단일한 용어와 동일한 의미로 사용되는 형용사가 있다는 점이다.\\n둘째로, 특정한 의미가 있는 경우에는 각각 고유한 의미와 기능을 갖는 것으로 간주한다.\\n셋째로 공통의 의미에 대해 상이한 해석이 가능하다.\\n넷번째로는 동일하고 유사한 뜻으로 쓰이는 용어가 존재한다는 사실이다.\\n다섯번째로 공통된 의미는 상호작용을 통해서 만들어진다는 점에서 동일하다.\\n여섯 번째로 공통적인 개념은 각기'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x-hhKMwkxPv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SKT Ko-GPT 1.2B 모델\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\")"
      ],
      "metadata": {
        "id": "XSyGTwgIOOds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/text = '인공지능을 배우기 위해서는'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "gen_ids = model.generate(input_ids,\n",
        "                           max_length=256,\n",
        "                           repetition_penalty=2.0,\n",
        "                           pad_token_id=tokenizer.pad_token_id,\n",
        "                           eos_token_id=tokenizer.eos_token_id,\n",
        "                           bos_token_id=tokenizer.bos_token_id,\n",
        "                           use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFxNxir6OZsT",
        "outputId": "b25c23be-2736-48d2-d260-cc2f16d45e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인공지능을 배우기 위해서는 컴퓨터가 스스로 학습할 수 있는 알고리즘이 필요합니다. 이를 위해 AI는 인간의 뇌를 모방한 '딥러닝' 기술을 활용하고 있습니다. <unk>AI의 발전은 어디까지 왔나=인공지능(AI)은 이미 우리 생활 깊숙이 들어와 있습니다.\n",
            " 구글, 페이스북 등 글로벌 IT기업들은 앞다퉈 음성인식 비서 서비스를 선보이고 있고, 국내에서도 카카오톡과 같은 모바일 메신저 서비스에 탑재되는 사례가 늘고 있죠. 또 최근에는 스마트폰으로 음악을 듣는 것이 일상화되면서 음악 추천 기능도 속속 등장했습니다.\n",
            " 이처럼 다양한 분야에서 지능형 로봇 기술이 적용되고 있지만 아직까지는 사람의 도움 없이 혼자 모든 일을 처리하는 것은 불가능합니다.\n",
            " 하지만 머지않아 이러한 한계를 극복하는 날이 올 것으로 보입니다. 바로 자율주행차가 그 주인공입니다. 자동차와 사람이 함께 주행하면서 사람과 사물을 연결하는 기술로, 운전자가 없는 무인자동차를 말하는데요. 이 기술은 현재 미국 실리콘밸리에서 개발 중인 차량용 인포테인먼트 시스템에서 가장 먼저 구현될 전망입니다.\n",
            " 특히 최근 들어 완성차 업체들이 잇따라 관련 신기술을 공개하며 시장 선점에 나서고 있는데요. 현대자동차그룹은 지난 1월 세계 최초로 고속도로 및 도심 도로 환경에서 완전자율주행이 가능한 차세대 수소전기트럭 콘셉트를 공개한 바 있죠.\n",
            " 현대차그룹 관계자는 \"완전자동차는 물론이고, 전기차와 하이브리드차, 플러\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "rOQ9YkoxyJmP",
        "outputId": "8c7f83e4-3e7e-4930-bcdf-001994fee16d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "WNbPiT_fyMCN",
        "outputId": "a0180551-7925-43e7-cf31-6c95c223ea3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement AutoModelForCausalLM (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for AutoModelForCausalLM\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 카카오브레인 KoGPT\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
        "  bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]'\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
        "  pad_token_id=tokenizer.eos_token_id,\n",
        "  torch_dtype='auto', low_cpu_mem_usage=True\n",
        ").to(device='cuda', non_blocking=True)\n",
        "_ = model.eval()\n",
        "\n",
        "prompt = '너는 누가 만들었어?'\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(tokens, do_sample=True, temperature=0.8, max_length=64)\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "\n",
        "print(generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "53ff0153a493432aacb6a291aaea0629",
            "e72a68747aac495b9926eabc72c9716f",
            "a66eb3a7f6904b468fd73fbe77ef004f",
            "97d68601ae194a91abbb30d1054fd122",
            "41dfe437055f4892a13f27cc8b6de23f",
            "a2918b8e585b420c9ef9c4d2d5ff9e39",
            "3a4b124a2da84dad9142b7a6c9af7db8",
            "7590f4bb1fca461aa7893f82999e21e5",
            "78227ed432794353b02458788ee6e0a0",
            "7c67ee085b674b9a82ce2368b0276a08",
            "e011b6fbbc374ebe9e882fc74dec0077"
          ]
        },
        "id": "Lrw2L35Ym2e_",
        "outputId": "78a2529e-bb65-4904-ac4c-9d1941d48ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/12.3G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53ff0153a493432aacb6a291aaea0629"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JU-5A5ETyAut"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}